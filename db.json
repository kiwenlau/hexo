{"meta":{"version":1,"warehouse":"1.0.2"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1},{"_id":"source/image/150918/kiwenlau_single_mesos.graffle","path":"image/150918/kiwenlau_single_mesos.graffle","modified":1},{"_id":"source/image/150918/hello.png","path":"image/150918/hello.png","modified":1},{"_id":"source/image/150918/architecuture.png","path":"image/150918/architecuture.png","modified":1},{"_id":"source/image/150918/Mesos.png","path":"image/150918/Mesos.png","modified":1},{"_id":"source/image/150918/Marathon.png","path":"image/150918/Marathon.png","modified":1},{"_id":"source/image/150626/grep_word.png","path":"image/150626/grep_word.png","modified":1},{"_id":"source/image/150623/tr-sed-newline.png","path":"image/150623/tr-sed-newline.png","modified":1},{"_id":"source/image/150621/python-substring.png","path":"image/150621/python-substring.png","modified":1},{"_id":"source/image/150620/ssh-copy-id.png","path":"image/150620/ssh-copy-id.png","modified":1},{"_id":"source/image/150608/image architecture.jpg","path":"image/150608/image architecture.jpg","modified":1},{"_id":"themes/light/source/kiwenlau.jpg","path":"kiwenlau.jpg","modified":1},{"_id":"themes/light/source/kiwenlau.ico","path":"kiwenlau.ico","modified":1},{"_id":"themes/light/source/js/jquery.imagesloaded.min.js","path":"js/jquery.imagesloaded.min.js","modified":1},{"_id":"themes/light/source/js/gallery.js","path":"js/gallery.js","modified":1},{"_id":"themes/light/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":1},{"_id":"themes/light/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":1},{"_id":"themes/light/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":1},{"_id":"themes/light/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":1},{"_id":"themes/light/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":1},{"_id":"themes/light/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":1},{"_id":"themes/light/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":1},{"_id":"themes/light/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":1},{"_id":"themes/light/source/css/style.styl","path":"css/style.styl","modified":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.woff","path":"css/font/fontawesome-webfont.woff","modified":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.ttf","path":"css/font/fontawesome-webfont.ttf","modified":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.svg","path":"css/font/fontawesome-webfont.svg","modified":1},{"_id":"themes/light/source/css/font/fontawesome-webfont.eot","path":"css/font/fontawesome-webfont.eot","modified":1}],"Cache":[{"_id":"source/CNAME","shasum":"abcdc15ac03b8fdb087e2ae5c120ef20dd63dcd1","modified":1433732308000},{"_id":"source/_posts/150608-hadoop-cluster-docker.md","shasum":"b03799f1c93041d334614672f312e4189ba69afc","modified":1443167508000},{"_id":"source/_posts/150620-ssh-copy-id-error.md","shasum":"4011d5afe85c583c0fb564639c541ef41c3da0bb","modified":1442554778000},{"_id":"source/_posts/150621-python-get-substring.md","shasum":"32c39e8c770c3df18603f9b5983d8200dc34a57e","modified":1443167690000},{"_id":"source/_posts/150623-tr-sed-newline.md","shasum":"36930cd381eafdad62989932ed3e612c2995ac10","modified":1443167710000},{"_id":"source/_posts/150626-grep-multiple-word.md","shasum":"c87b595b9b3450392e48ad8852d378fd23e171e1","modified":1443167735000},{"_id":"source/_posts/150918-single-mesos-docker.md","shasum":"edba8c5a27c473c84f46e22adf28c3059be1399a","modified":1443167326000},{"_id":"source/google6c2fe14874348911.html","shasum":"13b1c75c0ffea7dd64b61e99c75e328e81812700","modified":1433934386000},{"_id":"source/image/150608/image architecture.jpg","shasum":"450f2dffe1127f102221a9b3c934eb6054876d85","modified":1433822708000},{"_id":"source/image/150620/ssh-copy-id.png","shasum":"7cfa4736885fd48039e14eb57130c1d7278f7254","modified":1434791520000},{"_id":"source/image/150621/python-substring.png","shasum":"fe43b66a9024cc27c634badcb783b03fbbf5fc9b","modified":1434872276000},{"_id":"source/image/150623/tr-sed-newline.png","shasum":"ef261eaa115e62ae593299bd54b004b52302c9a9","modified":1435053026000},{"_id":"source/image/150626/grep_word.png","shasum":"3db90e0fc83c8e1e2aad60b3a09d72ccd35513c8","modified":1435279172000},{"_id":"source/image/150918/architecuture.png","shasum":"43b51d2b17bb54c7c11530d40f1068a558ebde10","modified":1442408879000},{"_id":"source/image/150918/kiwenlau_single_mesos.graffle","shasum":"3fcf8e0540f83077eac1114e5b431e64886f19ca","modified":1442407988000},{"_id":"source/image/150918/Marathon.png","shasum":"58abd8a1ba30eedef47649093a37291e29f21e00","modified":1442402866000},{"_id":"source/image/150918/hello.png","shasum":"732ba80324b66a3ff47fafbde89f4c61dfb04a08","modified":1442471270000},{"_id":"themes/light/source/css/_base/utils.styl","shasum":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1433597960000},{"_id":"themes/light/LICENSE","shasum":"c6f301bc722f0af3a55267a36c1c147aeddc6e46","modified":1433597960000},{"_id":"themes/light/README.md","shasum":"aa189c7ff03c60d8fceb009f5fca1a61d8a0ecdf","modified":1433597960000},{"_id":"themes/light/_config.yml","shasum":"c3729dc713e5b3dc3a1d5bf0ac1be76bf997a8bf","modified":1433929122000},{"_id":"themes/light/languages/de.yml","shasum":"e076c7f2eb29ebcfb04d94861bf3063c4b08078c","modified":1433597960000},{"_id":"themes/light/languages/default.yml","shasum":"fd7397be7789b43c1c163ab4faf106318811c2a8","modified":1433597960000},{"_id":"themes/light/languages/ru.yml","shasum":"35aadf8fdd28aaff8a1c8f50e80201dcf8ce0604","modified":1433597960000},{"_id":"themes/light/languages/es.yml","shasum":"de273af604b27812cfd4195e7b7f28ceff2734b3","modified":1433597960000},{"_id":"themes/light/languages/zh-CN.yml","shasum":"ca0118e9081b54cc0fca8596660bd6acf4c0308f","modified":1433597960000},{"_id":"themes/light/languages/zh-TW.yml","shasum":"6141b4c7a094c74bd9df7c08908d92b561c1a0c0","modified":1433597960000},{"_id":"themes/light/layout/_partial/after_footer.ejs","shasum":"e3fc00ab06a8e41051602b65ef8a4f968a4bf2bb","modified":1433941216000},{"_id":"themes/light/layout/_partial/archive.ejs","shasum":"7e4f7c2909b1b90241424ea2ff8e7b4761d8360f","modified":1433597960000},{"_id":"themes/light/layout/_partial/article.ejs","shasum":"bcae2ea030e69242d938c33094fc60207bf25e22","modified":1433609506000},{"_id":"themes/light/layout/_partial/comment.ejs","shasum":"c5409a6920f96816506b4e0d5dfae13449021654","modified":1433609464000},{"_id":"themes/light/layout/_partial/facebook_comment.ejs","shasum":"3fdc1d0ce9177825e7417635fbc545a35d528d04","modified":1433597960000},{"_id":"themes/light/layout/_partial/footer.ejs","shasum":"61224149335ae515b0c23e27070c11b05d78749d","modified":1434024998000},{"_id":"themes/light/layout/_partial/google_analytics.ejs","shasum":"7cf0d1f93051bda510d49dab7f684b9d7c6ba58f","modified":1433597960000},{"_id":"themes/light/layout/_partial/head.ejs","shasum":"d892420cbd253bf8707da7affb8f489cebaae6fd","modified":1433941148000},{"_id":"themes/light/layout/_partial/header.ejs","shasum":"d9a99aca97d8b41ed907fbf5b25df05da3ffa4f6","modified":1433597960000},{"_id":"themes/light/layout/_partial/pagination.ejs","shasum":"1206b630a07444e8744365f14ddb26095c925ae1","modified":1433597960000},{"_id":"themes/light/layout/_partial/post/category.ejs","shasum":"be740939c5c2d4ffdbed9557b4e63a590058b476","modified":1433597960000},{"_id":"themes/light/layout/_partial/post/gallery.ejs","shasum":"fafc2501d7e65983b0f5c2b58151ca12e57c0574","modified":1433597960000},{"_id":"themes/light/layout/_partial/post/share.ejs","shasum":"24c04b319f1b19e887c42db961b90a7e0ab26fdc","modified":1433597960000},{"_id":"themes/light/layout/_partial/post/tag.ejs","shasum":"095418df66a27a28cbab16d7cb0d16001b0e23f1","modified":1433597960000},{"_id":"themes/light/layout/_partial/post/title.ejs","shasum":"d7fbc575d35ae68f9045a382c651450e4131f335","modified":1433597960000},{"_id":"themes/light/layout/_partial/sidebar.ejs","shasum":"caf351797a18d03d8ee945ceb9f83785c50c09f9","modified":1433597960000},{"_id":"themes/light/layout/_widget/category.ejs","shasum":"8a2b90dc29661371f060f710668929c3588e15e4","modified":1433597960000},{"_id":"themes/light/layout/_widget/link.ejs","shasum":"a7e48cd1e18b4a0608dc81a6a50674d9cd30e858","modified":1442558797000},{"_id":"themes/light/layout/_widget/photo.ejs","shasum":"a985f891ccad6a54352c38de34e90e14005c3e04","modified":1442554487000},{"_id":"themes/light/layout/_widget/recent_posts.ejs","shasum":"8f2f3963bd568c681d7585bb8099fb1b3e1d4c81","modified":1442555459000},{"_id":"themes/light/layout/_widget/search.ejs","shasum":"55c707f3aa7453c305c41898ad22556edd213830","modified":1433597960000},{"_id":"themes/light/layout/_widget/tag.ejs","shasum":"1914db78bea49c333067d79fe7ad9567d2b08d00","modified":1433597960000},{"_id":"themes/light/layout/_widget/tagcloud.ejs","shasum":"673b598903e1b2b9d9ea31dc79bab65ef3984348","modified":1433929542000},{"_id":"themes/light/layout/archive.ejs","shasum":"a18842e3d719fe3ca9b977a6995f8facc75c8673","modified":1433597960000},{"_id":"themes/light/layout/category.ejs","shasum":"9b740fc33f6f028df60f0bc4312bf3ebd03aa8ea","modified":1433597960000},{"_id":"themes/light/layout/index.ejs","shasum":"e569d8fe0741a24efb89e44781f9e616da17e036","modified":1433597960000},{"_id":"themes/light/layout/layout.ejs","shasum":"72da76881ebf00e71d7cc196f377e37a17ec7a6f","modified":1433597960000},{"_id":"themes/light/layout/page.ejs","shasum":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1433597960000},{"_id":"themes/light/layout/post.ejs","shasum":"70cbc9854655773cc6ba84eecaaf330fed430465","modified":1433597960000},{"_id":"themes/light/layout/tag.ejs","shasum":"45150a2365768b6b67880193c9264ad2bb4814db","modified":1433597960000},{"_id":"themes/light/source/css/_base/layout.styl","shasum":"1b58c21aa48a8f9f7f811af681ac182dd058e23d","modified":1433597960000},{"_id":"themes/light/source/css/_base/variable.styl","shasum":"c4e07cb7f4ec980553cd19d9d2cd8a1a44d4cd82","modified":1434027874000},{"_id":"themes/light/source/css/_partial/archive.styl","shasum":"072e9b8c5ee9acf95ac7cce9c34706d41e412229","modified":1433597960000},{"_id":"themes/light/source/css/_partial/article.styl","shasum":"09e00a528f2524093660cf96647282aa2b98abbf","modified":1434030084000},{"_id":"themes/light/source/css/_partial/comment.styl","shasum":"a74254a6e713a522134cca4c644fde681c502823","modified":1434028066000},{"_id":"themes/light/source/css/_partial/footer.styl","shasum":"1757872dbdbd09295a625f13e356aa798a8bb308","modified":1433597960000},{"_id":"themes/light/source/css/_partial/header.styl","shasum":"0f932c9514d13fea70fe109242e17ee633a2b28a","modified":1434021576000},{"_id":"themes/light/source/css/_partial/index.styl","shasum":"7a8c0ec6ab99a9f8e00c9687aca29d31752424a2","modified":1433597960000},{"_id":"themes/light/source/css/_partial/sidebar.styl","shasum":"1bdd787d9dc40829dcab26e0e4543c0d2325b5b8","modified":1434022784000},{"_id":"themes/light/source/css/_partial/syntax.styl","shasum":"031903fe83aa7d9960bd084f4bb77a6671abcbfa","modified":1443169038000},{"_id":"themes/light/source/css/font/fontawesome-webfont.eot","shasum":"d775f599ff3f23be082e6a9604b4898718923a37","modified":1433597960000},{"_id":"themes/light/source/css/font/fontawesome-webfont.woff","shasum":"0612cddf2f835cceffccc88fd194f97367d0b024","modified":1433597960000},{"_id":"themes/light/source/css/style.styl","shasum":"c03b2520e4a85b981e29516cadc0a365e6500e3d","modified":1433597960000},{"_id":"themes/light/source/fancybox/blank.gif","shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1433597960000},{"_id":"themes/light/source/fancybox/fancybox_loading.gif","shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1433597960000},{"_id":"themes/light/source/fancybox/fancybox_loading@2x.gif","shasum":"273b123496a42ba45c3416adb027cd99745058b0","modified":1433597960000},{"_id":"themes/light/source/fancybox/fancybox_overlay.png","shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1433597960000},{"_id":"themes/light/source/fancybox/fancybox_sprite.png","shasum":"17df19f97628e77be09c352bf27425faea248251","modified":1433597960000},{"_id":"themes/light/source/fancybox/fancybox_sprite@2x.png","shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1433597960000},{"_id":"themes/light/source/fancybox/jquery.fancybox.css","shasum":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1433597960000},{"_id":"themes/light/source/fancybox/jquery.fancybox.pack.js","shasum":"53360764b429c212f424399384417ccc233bb3be","modified":1433597960000},{"_id":"themes/light/source/js/gallery.js","shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed","modified":1433597960000},{"_id":"themes/light/source/js/jquery.imagesloaded.min.js","shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f","modified":1433597960000},{"_id":"source/image/150918/Mesos.png","shasum":"c21fb25a6da8801ecb9b6b25888cb88da16790b4","modified":1442402816000},{"_id":"themes/light/source/css/font/fontawesome-webfont.svg","shasum":"d162419c91b8bab3a4fd327c933a0fcf3799c251","modified":1433597960000},{"_id":"themes/light/source/css/font/fontawesome-webfont.ttf","shasum":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c","modified":1433597960000},{"_id":"themes/light/source/kiwenlau.ico","shasum":"987d9c1658c3779037d96f49d8779b9bab18440b","modified":1433759880000},{"_id":"themes/light/source/kiwenlau.jpg","shasum":"e163949f9617ee5a0b92ef131f6e2bb57a2c0e36","modified":1433690104000},{"_id":"public/CNAME","modified":1443169236262,"shasum":"abcdc15ac03b8fdb087e2ae5c120ef20dd63dcd1"},{"_id":"public/image/150918/kiwenlau_single_mesos.graffle","modified":1443169236278,"shasum":"3fcf8e0540f83077eac1114e5b431e64886f19ca"},{"_id":"public/image/150918/hello.png","modified":1443169236291,"shasum":"732ba80324b66a3ff47fafbde89f4c61dfb04a08"},{"_id":"public/image/150918/architecuture.png","modified":1443169236299,"shasum":"43b51d2b17bb54c7c11530d40f1068a558ebde10"},{"_id":"public/image/150918/Mesos.png","modified":1443169236306,"shasum":"c21fb25a6da8801ecb9b6b25888cb88da16790b4"},{"_id":"public/image/150918/Marathon.png","modified":1443169236314,"shasum":"58abd8a1ba30eedef47649093a37291e29f21e00"},{"_id":"public/image/150626/grep_word.png","modified":1443169236321,"shasum":"3db90e0fc83c8e1e2aad60b3a09d72ccd35513c8"},{"_id":"public/image/150623/tr-sed-newline.png","modified":1443169236332,"shasum":"ef261eaa115e62ae593299bd54b004b52302c9a9"},{"_id":"public/image/150621/python-substring.png","modified":1443169236340,"shasum":"fe43b66a9024cc27c634badcb783b03fbbf5fc9b"},{"_id":"public/image/150620/ssh-copy-id.png","modified":1443169236345,"shasum":"7cfa4736885fd48039e14eb57130c1d7278f7254"},{"_id":"public/image/150608/image architecture.jpg","modified":1443169236352,"shasum":"450f2dffe1127f102221a9b3c934eb6054876d85"},{"_id":"public/kiwenlau.jpg","modified":1443169236390,"shasum":"e163949f9617ee5a0b92ef131f6e2bb57a2c0e36"},{"_id":"public/kiwenlau.ico","modified":1443169236406,"shasum":"987d9c1658c3779037d96f49d8779b9bab18440b"},{"_id":"public/js/jquery.imagesloaded.min.js","modified":1443169236411,"shasum":"4109837b1f6477bacc6b095a863b1b95b1b3693f"},{"_id":"public/js/gallery.js","modified":1443169236416,"shasum":"f8a4ba7fb8349cca374a3c69fff9b2bf21f742ed"},{"_id":"public/fancybox/jquery.fancybox.pack.js","modified":1443169236430,"shasum":"53360764b429c212f424399384417ccc233bb3be"},{"_id":"public/fancybox/jquery.fancybox.css","modified":1443169236440,"shasum":"5f163444617b6cf267342f06ac166a237bb62df9"},{"_id":"public/fancybox/fancybox_sprite@2x.png","modified":1443169236451,"shasum":"30c58913f327e28f466a00f4c1ac8001b560aed8"},{"_id":"public/fancybox/fancybox_sprite.png","modified":1443169236459,"shasum":"17df19f97628e77be09c352bf27425faea248251"},{"_id":"public/fancybox/fancybox_overlay.png","modified":1443169236469,"shasum":"b3a4ee645ba494f52840ef8412015ba0f465dbe0"},{"_id":"public/fancybox/fancybox_loading@2x.gif","modified":1443169236481,"shasum":"273b123496a42ba45c3416adb027cd99745058b0"},{"_id":"public/fancybox/fancybox_loading.gif","modified":1443169236486,"shasum":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c"},{"_id":"public/fancybox/blank.gif","modified":1443169236498,"shasum":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a"},{"_id":"public/css/style.css","modified":1443169237079,"shasum":"df9188017cc02f2f3eab54caf4ca3f185f756efd"},{"_id":"public/css/font/fontawesome-webfont.woff","modified":1443169237359,"shasum":"0612cddf2f835cceffccc88fd194f97367d0b024"},{"_id":"public/css/font/fontawesome-webfont.ttf","modified":1443169237370,"shasum":"a9468f6a1fe965fbcaf5a1bd6c11705e2fc5f84c"},{"_id":"public/css/font/fontawesome-webfont.svg","modified":1443169237382,"shasum":"d162419c91b8bab3a4fd327c933a0fcf3799c251"},{"_id":"public/css/font/fontawesome-webfont.eot","modified":1443169237395,"shasum":"d775f599ff3f23be082e6a9604b4898718923a37"},{"_id":"public/google6c2fe14874348911.html","modified":1443169237403,"shasum":"12e5058baee67bcef931133e10cf113179e7d1eb"},{"_id":"public/2015/09/18/150918-single-mesos-docker/index.html","modified":1443169237427,"shasum":"e0d4652b4eac2910993b9b14085c90a270435100"},{"_id":"public/2015/06/26/150626-grep-multiple-word/index.html","modified":1443169237437,"shasum":"6f5d19e4071d3715696e58f17b3c8616b87fae28"},{"_id":"public/2015/06/23/150623-tr-sed-newline/index.html","modified":1443169237458,"shasum":"337d60169b225b891b35327fd96ddfb319f4e74b"},{"_id":"public/2015/06/21/150621-python-get-substring/index.html","modified":1443169237480,"shasum":"3f2414863dcf15353afa76dbb90eecb8d6f8004e"},{"_id":"public/2015/06/20/150620-ssh-copy-id-error/index.html","modified":1443169237498,"shasum":"78e5513711662afd0d5642841d2af7f51ff3bcaf"},{"_id":"public/2015/06/08/150608-hadoop-cluster-docker/index.html","modified":1443169237516,"shasum":"70f51f518097b4df86d31fdaad02bf0b1ac87b3b"},{"_id":"public/archives/index.html","modified":1443169237527,"shasum":"47234bf601acf3524d686f6e77ddb04a6cffed8c"},{"_id":"public/archives/2015/index.html","modified":1443169237540,"shasum":"4ecc5bdc48a29c5c93b452d5c27beea4803ebae0"},{"_id":"public/archives/2015/06/index.html","modified":1443169237553,"shasum":"e5998090e0470fa72e8dd8b296726dfd9a1f897b"},{"_id":"public/archives/2015/09/index.html","modified":1443169237572,"shasum":"9c3fdcd64b26c01d635bf22d2dee5d832fb6890d"},{"_id":"public/tags/Docker/index.html","modified":1443169237594,"shasum":"197d26f724304309fba128bc973d74af81b275fc"},{"_id":"public/tags/Mesos/index.html","modified":1443169237607,"shasum":"0c42b3e0462caf6988d7656986549bf3de2401e8"},{"_id":"public/tags/Marathon/index.html","modified":1443169237625,"shasum":"8a701092a3cb2e9994fbbc0c5d870cc278467cfe"},{"_id":"public/tags/Linux/index.html","modified":1443169237639,"shasum":"7d1cdbfc44192c81010f4d314be8d0cee6b98ba9"},{"_id":"public/tags/Python/index.html","modified":1443169237654,"shasum":"12c301d5a54a10bb4e95cf6c19dea6fa1e4f3b4a"},{"_id":"public/tags/Hadoop/index.html","modified":1443169237666,"shasum":"21505eee08d4f40a739093d75a8b514fb6b275ee"},{"_id":"public/index.html","modified":1443169237694,"shasum":"e611abd69f744776d6192c66dbf3cf32cce11eb4"},{"_id":"public/atom.xml","modified":1443169237702,"shasum":"d04e13be5f66ab6a432cce3c93b9f79113ffd6e9"},{"_id":"public/sitemap.xml","modified":1443169237707,"shasum":"97e43246d1516173c6714d0608011150af0186de"}],"Category":[],"Data":[],"Page":[{"layout":"false","_content":"google-site-verification: google6c2fe14874348911.html","source":"google6c2fe14874348911.html","raw":"layout: false\n---\ngoogle-site-verification: google6c2fe14874348911.html","date":"2015-07-03T08:47:54.000Z","updated":"2015-06-10T11:06:26.000Z","path":"google6c2fe14874348911.html","title":"","comments":1,"_id":"ciezdp84o00006cv7u419hmge"}],"Post":[{"title":"基于Docker快速搭建单节点Mesos/Marathon集群","date":"2015-09-18T03:00:00.000Z","_content":"\n- GitHub地址：[kiwenlau/single-mesos-docker](https://github.com/kiwenlau/single-mesos-docker)\n- 博客地址：[基于Docker快速搭建单节点Mesos/Marathon集群](http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/)\n\n##一. 简介\n\n[Mesos](http://mesos.apache.org)是集群资源管理系统，[Marathon](http://mesosphere.github.io/marathon)是运行在Mesos之上的集群计算架构。将Mesos和Marathon打包到[Docker](https://www.docker.com/)镜像中，开发者便可以在本机上快速搭建Mesos/Marathon集群，进行学习和测试。\n\n**kiwenlau/single-mesos**镜像非常简单。Docker容器运行在Ubuntu主机之上，Mesos和Marathon运行在该容器之中。具体来讲，Docker容器中运行了一个Mesos Master和一个Mesos Slave，以及Marathon和[ZooKeeper](https://zookeeper.apache.org/)。集群架构如下图：\n\n![](/image/150918/architecuture.png)\n\n\n##二. 搭建Mesos/Marathon集群\n\n**1. 下载Docker镜像:**\n\n```sh\nsudo docker pull kiwenlau/single-mesos:3.0\n```\n\n**2. 运行Docker容器:**\n\n```sh\nsudo docker run -p 5050:5050 -p 8080:8080 --name mesos -it -w /root kiwenlau/single-mesos:3.0\n```\n\ndocker run命令运行成功后即进入容器内部，以下为输出：\n\n```bash\nStart ZooKeeper...\nStart Mesos master...\nStart Mesos slave...\nStart Marathon...\n```\n\n\n##三. 测试Mesos/Marathon集群\n\n**1. 通过curl命令调用Marathon的REST API, 创建一个hello程序：**\n\n```sh\ncurl -v -H \"Content-Type: application/json\" -X POST --data \"@hello.json\" http://127.0.0.1:8080/v2/apps\n```\n\n下面为hello.json。由cmd可知，该程序每隔1秒往output.txt文件中写入hello。\n\n```bash\n{\n  \"id\": \"hello\",\n  \"cmd\": \"while [ true ] ; do echo hello >> /root/output.txt; sleep 1; done\",\n  \"cpus\": 0.1,\n  \"mem\": 10.0,\n  \"instances\": 1\n}\n```\n\ncurl执行结果:\n\n```bash\n* Hostname was NOT found in DNS cache\n*   Trying 127.0.0.1...\n* Connected to 127.0.0.1 (127.0.0.1) port 8080 (#0)\n> POST /v2/apps HTTP/1.1\n> User-Agent: curl/7.35.0\n> Host: 127.0.0.1:8080\n> Accept: */*\n> Content-Type: application/json\n> Content-Length: 139\n> \n* upload completely sent off: 139 out of 139 bytes\n< HTTP/1.1 201 Created\n< X-Marathon-Leader: http://ec054cabb9af:8080\n< Cache-Control: no-cache, no-store, must-revalidate\n< Pragma: no-cache\n< Expires: 0\n< Location: http://127.0.0.1:8080/v2/apps/hello\n< Content-Type: application/json; qs=2\n< Transfer-Encoding: chunked\n* Server Jetty(8.y.z-SNAPSHOT) is not blacklisted\n< Server: Jetty(8.y.z-SNAPSHOT)\n< \n* Connection #0 to host 127.0.0.1 left intact\n{\"id\":\"/hello\",\"cmd\":\"while [ true ] ; do echo hello >> /root/output.txt; sleep 1; done\",\"args\":null,\"user\":null,\"env\":{},\"instances\":1,\"cpus\":0.1,\"mem\":10.0,\"disk\":0.0,\"executor\":\"\",\"constraints\":[],\"uris\":[],\"storeUrls\":[],\"ports\":[0],\"requirePorts\":false,\"backoffFactor\":1.15,\"container\":null,\"healthChecks\":[],\"dependencies\":[],\"upgradeStrategy\":{\"minimumHealthCapacity\":1.0,\"maximumOverCapacity\":1.0},\"labels\":{},\"acceptedResourceRoles\":null,\"version\":\"2015-09-16T11:22:27.967Z\",\"deployments\":[{\"id\":\"2cd2fdd4-e5f9-4088-895f-7976349b7a19\"}],\"tasks\":[],\"tasksStaged\":0,\"tasksRunning\":0,\"tasksHealthy\":0,\"tasksUnhealthy\":0,\"backoffSeconds\":1,\"maxLaunchDelaySeconds\":3600}\n```\n\n**2. 查看hello程序的运行结果：**\n\n```sh\ntail -f output.txt\n```\n当你看到终端不断输出\"hello\"时说明运行成功。\n\n**3. 使用浏览器查看Mesos和Marathon的网页管理界面**\n\n**注意**将IP替换运行Docker容器的主机IP地址\n\nMesos网页管理界面地址：[http://192.168.59.10:5050](http://192.168.59.10:5050)\n\nMesos网页管理界面如图，可知hello程序正在运行：\n\n![](/image/150918/Mesos.png)\n\nMarathon网页管理界面地址：[http://192.168.59.10:8080](http://192.168.59.10:8080)\n\nMarathon网页管理界面如图，可知hello程序正在运行：\n\n![](/image/150918/Marathon.png)\n\n**4. 通过Marathon网页管理界面创建测试程序**\n\n在Marathon的网页管理界面上点击\"New APP\"，在弹框中配置测试程序。ID为\"hello\", Command为\"echo hello >> /root/output.txt\", 然后点击\"Create\"即可。如下图：\n\n![](/image/150918/hello.png)\n\n\n##四. 存在的问题\n\n其实，参考[Setting up a Single Node Mesosphere Cluster](https://open.mesosphere.com/getting-started/developer/single-node-install/)，可以很快地在ubuntu主机上直接搭建一个单节点的Mesos/Marathon集群。但是，当我安装该教程的步骤将Mesos/Marathon集群打包到Docker镜像中时，遇到了一个比较奇怪的问题。\n\n在Docker容器中使用**\"sudo service mesos-master start\"**和**\"sudo service mesos-slave start\"**命令启动Mesos Master和Mesos Slave时，出现**\"mesos-master: unrecognized service\"**和**\"mesos-slave: unrecognized service\"**错误。但是，我在ubuntu主机上安装Mesos/Marathon集群后，使用同样的命令启动Mesos并没有问题。后来，我是通过直接执行mesos-master和mesos-slave命令启动Mesos，命令如下：\n\n```sh\n/usr/sbin/mesos-master --zk=zk://127.0.0.1:2181/mesos --quorum=1 --work_dir=/var/lib/mesos --log_dir=/log/mesos  \n```\n\n```sh\n/usr/sbin/mesos-slave --master=zk://127.0.0.1:2181/mesos --log_dir=/log/mesos\n```\n\n由这个问题可知，虽然在Docker容器几乎可以运行任意程序，似乎和Ubuntu主机没有区别。但是事实上，**Docker容器与ubuntu主机并非完全一致**，而且这些细节的不同点比较坑。这一点很值得探讨，可以让大家在使用Docker时少走些弯路。对于提到的问题，虽然是解决了，然而我仍然不清楚其中的原因:(\n\n\n##五. Docker镜像备份\n\n我将Docker镜像上传到了灵雀云（Alaudo）的Docker仓库，可以通过以下命令下载和运行：\n\n```sh\nsudo docker pull index.alauda.cn/kiwenlau/single-mesos:3.0\n```\n\n```sh\nsudo docker run -p 5050:5050 -p 8080:8080 --name mesos -it -w /root index.alauda.cn/kiwenlau/single-mesos:3.0\n```\n\n##六. 参考\n\n1. [Setting up a Single Node Mesosphere Cluster](https://open.mesosphere.com/getting-started/developer/single-node-install/)\n2. [Setting up a Cluster on Mesos and Marathon](https://open.mesosphere.com/getting-started/datacenter/install/#master-setup)\n3. [An Introduction to Mesosphere](https://www.digitalocean.com/community/tutorials/an-introduction-to-mesosphere)\n4. [How To Configure a Production-Ready Mesosphere Cluster on Ubuntu 14.04](https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04)\n5. [Deploy a Mesos Cluster with 7 Commands Using Docker](https://medium.com/@gargar454/deploy-a-mesos-cluster-with-7-commands-using-docker-57951e020586)\n6. [sekka1/mesosphere-docker](https://github.com/sekka1/mesosphere-docker)\n7. [Marathon: Application Basics](http://mesosphere.github.io/marathon/docs/application-basics.html)\n8. [Marathon: REST API](http://mesosphere.github.io/marathon/docs/rest-api.html)\n\n***\n**版权声明**\n\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文URL地址：\n\n[http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/](http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/)\n***\n\n\n\n\n\n","source":"_posts/150918-single-mesos-docker.md","raw":"title: 基于Docker快速搭建单节点Mesos/Marathon集群\n\ndate: 2015-09-18 12:00:00\n\ntags: [Docker,Mesos,Marathon]\n\n---\n\n- GitHub地址：[kiwenlau/single-mesos-docker](https://github.com/kiwenlau/single-mesos-docker)\n- 博客地址：[基于Docker快速搭建单节点Mesos/Marathon集群](http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/)\n\n##一. 简介\n\n[Mesos](http://mesos.apache.org)是集群资源管理系统，[Marathon](http://mesosphere.github.io/marathon)是运行在Mesos之上的集群计算架构。将Mesos和Marathon打包到[Docker](https://www.docker.com/)镜像中，开发者便可以在本机上快速搭建Mesos/Marathon集群，进行学习和测试。\n\n**kiwenlau/single-mesos**镜像非常简单。Docker容器运行在Ubuntu主机之上，Mesos和Marathon运行在该容器之中。具体来讲，Docker容器中运行了一个Mesos Master和一个Mesos Slave，以及Marathon和[ZooKeeper](https://zookeeper.apache.org/)。集群架构如下图：\n\n![](/image/150918/architecuture.png)\n\n\n##二. 搭建Mesos/Marathon集群\n\n**1. 下载Docker镜像:**\n\n```sh\nsudo docker pull kiwenlau/single-mesos:3.0\n```\n\n**2. 运行Docker容器:**\n\n```sh\nsudo docker run -p 5050:5050 -p 8080:8080 --name mesos -it -w /root kiwenlau/single-mesos:3.0\n```\n\ndocker run命令运行成功后即进入容器内部，以下为输出：\n\n```bash\nStart ZooKeeper...\nStart Mesos master...\nStart Mesos slave...\nStart Marathon...\n```\n\n\n##三. 测试Mesos/Marathon集群\n\n**1. 通过curl命令调用Marathon的REST API, 创建一个hello程序：**\n\n```sh\ncurl -v -H \"Content-Type: application/json\" -X POST --data \"@hello.json\" http://127.0.0.1:8080/v2/apps\n```\n\n下面为hello.json。由cmd可知，该程序每隔1秒往output.txt文件中写入hello。\n\n```bash\n{\n  \"id\": \"hello\",\n  \"cmd\": \"while [ true ] ; do echo hello >> /root/output.txt; sleep 1; done\",\n  \"cpus\": 0.1,\n  \"mem\": 10.0,\n  \"instances\": 1\n}\n```\n\ncurl执行结果:\n\n```bash\n* Hostname was NOT found in DNS cache\n*   Trying 127.0.0.1...\n* Connected to 127.0.0.1 (127.0.0.1) port 8080 (#0)\n> POST /v2/apps HTTP/1.1\n> User-Agent: curl/7.35.0\n> Host: 127.0.0.1:8080\n> Accept: */*\n> Content-Type: application/json\n> Content-Length: 139\n> \n* upload completely sent off: 139 out of 139 bytes\n< HTTP/1.1 201 Created\n< X-Marathon-Leader: http://ec054cabb9af:8080\n< Cache-Control: no-cache, no-store, must-revalidate\n< Pragma: no-cache\n< Expires: 0\n< Location: http://127.0.0.1:8080/v2/apps/hello\n< Content-Type: application/json; qs=2\n< Transfer-Encoding: chunked\n* Server Jetty(8.y.z-SNAPSHOT) is not blacklisted\n< Server: Jetty(8.y.z-SNAPSHOT)\n< \n* Connection #0 to host 127.0.0.1 left intact\n{\"id\":\"/hello\",\"cmd\":\"while [ true ] ; do echo hello >> /root/output.txt; sleep 1; done\",\"args\":null,\"user\":null,\"env\":{},\"instances\":1,\"cpus\":0.1,\"mem\":10.0,\"disk\":0.0,\"executor\":\"\",\"constraints\":[],\"uris\":[],\"storeUrls\":[],\"ports\":[0],\"requirePorts\":false,\"backoffFactor\":1.15,\"container\":null,\"healthChecks\":[],\"dependencies\":[],\"upgradeStrategy\":{\"minimumHealthCapacity\":1.0,\"maximumOverCapacity\":1.0},\"labels\":{},\"acceptedResourceRoles\":null,\"version\":\"2015-09-16T11:22:27.967Z\",\"deployments\":[{\"id\":\"2cd2fdd4-e5f9-4088-895f-7976349b7a19\"}],\"tasks\":[],\"tasksStaged\":0,\"tasksRunning\":0,\"tasksHealthy\":0,\"tasksUnhealthy\":0,\"backoffSeconds\":1,\"maxLaunchDelaySeconds\":3600}\n```\n\n**2. 查看hello程序的运行结果：**\n\n```sh\ntail -f output.txt\n```\n当你看到终端不断输出\"hello\"时说明运行成功。\n\n**3. 使用浏览器查看Mesos和Marathon的网页管理界面**\n\n**注意**将IP替换运行Docker容器的主机IP地址\n\nMesos网页管理界面地址：[http://192.168.59.10:5050](http://192.168.59.10:5050)\n\nMesos网页管理界面如图，可知hello程序正在运行：\n\n![](/image/150918/Mesos.png)\n\nMarathon网页管理界面地址：[http://192.168.59.10:8080](http://192.168.59.10:8080)\n\nMarathon网页管理界面如图，可知hello程序正在运行：\n\n![](/image/150918/Marathon.png)\n\n**4. 通过Marathon网页管理界面创建测试程序**\n\n在Marathon的网页管理界面上点击\"New APP\"，在弹框中配置测试程序。ID为\"hello\", Command为\"echo hello >> /root/output.txt\", 然后点击\"Create\"即可。如下图：\n\n![](/image/150918/hello.png)\n\n\n##四. 存在的问题\n\n其实，参考[Setting up a Single Node Mesosphere Cluster](https://open.mesosphere.com/getting-started/developer/single-node-install/)，可以很快地在ubuntu主机上直接搭建一个单节点的Mesos/Marathon集群。但是，当我安装该教程的步骤将Mesos/Marathon集群打包到Docker镜像中时，遇到了一个比较奇怪的问题。\n\n在Docker容器中使用**\"sudo service mesos-master start\"**和**\"sudo service mesos-slave start\"**命令启动Mesos Master和Mesos Slave时，出现**\"mesos-master: unrecognized service\"**和**\"mesos-slave: unrecognized service\"**错误。但是，我在ubuntu主机上安装Mesos/Marathon集群后，使用同样的命令启动Mesos并没有问题。后来，我是通过直接执行mesos-master和mesos-slave命令启动Mesos，命令如下：\n\n```sh\n/usr/sbin/mesos-master --zk=zk://127.0.0.1:2181/mesos --quorum=1 --work_dir=/var/lib/mesos --log_dir=/log/mesos  \n```\n\n```sh\n/usr/sbin/mesos-slave --master=zk://127.0.0.1:2181/mesos --log_dir=/log/mesos\n```\n\n由这个问题可知，虽然在Docker容器几乎可以运行任意程序，似乎和Ubuntu主机没有区别。但是事实上，**Docker容器与ubuntu主机并非完全一致**，而且这些细节的不同点比较坑。这一点很值得探讨，可以让大家在使用Docker时少走些弯路。对于提到的问题，虽然是解决了，然而我仍然不清楚其中的原因:(\n\n\n##五. Docker镜像备份\n\n我将Docker镜像上传到了灵雀云（Alaudo）的Docker仓库，可以通过以下命令下载和运行：\n\n```sh\nsudo docker pull index.alauda.cn/kiwenlau/single-mesos:3.0\n```\n\n```sh\nsudo docker run -p 5050:5050 -p 8080:8080 --name mesos -it -w /root index.alauda.cn/kiwenlau/single-mesos:3.0\n```\n\n##六. 参考\n\n1. [Setting up a Single Node Mesosphere Cluster](https://open.mesosphere.com/getting-started/developer/single-node-install/)\n2. [Setting up a Cluster on Mesos and Marathon](https://open.mesosphere.com/getting-started/datacenter/install/#master-setup)\n3. [An Introduction to Mesosphere](https://www.digitalocean.com/community/tutorials/an-introduction-to-mesosphere)\n4. [How To Configure a Production-Ready Mesosphere Cluster on Ubuntu 14.04](https://www.digitalocean.com/community/tutorials/how-to-configure-a-production-ready-mesosphere-cluster-on-ubuntu-14-04)\n5. [Deploy a Mesos Cluster with 7 Commands Using Docker](https://medium.com/@gargar454/deploy-a-mesos-cluster-with-7-commands-using-docker-57951e020586)\n6. [sekka1/mesosphere-docker](https://github.com/sekka1/mesosphere-docker)\n7. [Marathon: Application Basics](http://mesosphere.github.io/marathon/docs/application-basics.html)\n8. [Marathon: REST API](http://mesosphere.github.io/marathon/docs/rest-api.html)\n\n***\n**版权声明**\n\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文URL地址：\n\n[http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/](http://kiwenlau.com/2015/09/18/150918-single-mesos-docker/)\n***\n\n\n\n\n\n","slug":"150918-single-mesos-docker","published":1,"updated":"2015-09-25T07:48:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp84x00016cv7v0jwx54o"},{"title":"grep命令匹配多个单词","date":"2015-06-26T00:41:52.000Z","_content":"\n使用grep命令可以通过匹配单词迅速定位对应的行，但是有时候需要同时匹配多个单词，而且会有不同的匹配要求。本文将通过匹配两个单词作为示例，介绍grep匹配多个单词的方法。\n\n\n![](/image/150626/grep_word.png)\n\n\n**输入文本(country.txt)**\n```bash\nAustria England\nAustria Canada\nChina England\nChina Canada\n```\n\n**1. 匹配同时含两个单词的行**\n```sh\ncat country.txt | grep Austria | grep England\n```\n\n*输出*\n```plain\nAustria England\n```\n\n\n**2. 匹配两个单词都不存在的行**\n```sh\ncat country.txt | grep -v Austria | grep -v England\n```\n\n*输出*\n```plain\nChina Canada\n```\n\n**3. 匹配含有任意一个单词的行**\n```sh\ncat country.txt | grep -E 'Austria|England'\n```\n\n*输出*\n```bash\nAustria England\nAustria Canada\nChina England\n```\n\n**3. 匹配含有其中一个单词但是不含另一个单词的行**\n```sh\ncat country.txt | grep Austria | grep -v England\n```\n\n*输出*\n```plain\nAustria Canada\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/26/150626-grep-multiple-word/](http://kiwenlau.com/2015/06/26/150626-grep-multiple-word/)\n***\n\n\n\n\n\n\n\n\n","source":"_posts/150626-grep-multiple-word.md","raw":"title: grep命令匹配多个单词\n\ndate: 2015-06-26 09:41:52\n\ntags: [Linux]\n\n---\n\n使用grep命令可以通过匹配单词迅速定位对应的行，但是有时候需要同时匹配多个单词，而且会有不同的匹配要求。本文将通过匹配两个单词作为示例，介绍grep匹配多个单词的方法。\n\n\n![](/image/150626/grep_word.png)\n\n\n**输入文本(country.txt)**\n```bash\nAustria England\nAustria Canada\nChina England\nChina Canada\n```\n\n**1. 匹配同时含两个单词的行**\n```sh\ncat country.txt | grep Austria | grep England\n```\n\n*输出*\n```plain\nAustria England\n```\n\n\n**2. 匹配两个单词都不存在的行**\n```sh\ncat country.txt | grep -v Austria | grep -v England\n```\n\n*输出*\n```plain\nChina Canada\n```\n\n**3. 匹配含有任意一个单词的行**\n```sh\ncat country.txt | grep -E 'Austria|England'\n```\n\n*输出*\n```bash\nAustria England\nAustria Canada\nChina England\n```\n\n**3. 匹配含有其中一个单词但是不含另一个单词的行**\n```sh\ncat country.txt | grep Austria | grep -v England\n```\n\n*输出*\n```plain\nAustria Canada\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/26/150626-grep-multiple-word/](http://kiwenlau.com/2015/06/26/150626-grep-multiple-word/)\n***\n\n\n\n\n\n\n\n\n","slug":"150626-grep-multiple-word","published":1,"updated":"2015-09-25T07:55:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp85h00086cv7bu5iey8n"},{"title":"tr与sed命令将换行符替换为空","date":"2015-06-23T09:56:27.000Z","_content":"处理文本时需要将换行符替换为空格，若使用sed命令会比较麻烦，而使用tr命令非常方便。\n\n![](/image/150623/tr-sed-newline.png)\n\n**输入文本(country.txt)**\n```bash\nChina\nAmerica\nFrance\nGerman\n```\n\n**sed命令**(参考[sed命令替换换行符](http://my.oschina.net/shelllife/blog/118337))\n```sh\ncat country.txt | sed ':label;N;s/\\n/ /;b label'\n```\n\n**tr命令**\n```sh\ncat country.txt | tr \"\\n\" \" \"\n```\n\n**两个命令输出一致，但是sed命令的输出结尾有换行符，而tr命令的输出结尾没有换行符**\n```plain\nChina America France German\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：[http://kiwenlau.com/2015/06/23/150623-tr-sed-newline/](http://kiwenlau.com/2015/06/23/150623-tr-sed-newline/)\n***\n","source":"_posts/150623-tr-sed-newline.md","raw":"title: tr与sed命令将换行符替换为空\n\ndate: 2015-06-23 18:56:27\n\ntags: [Linux]\n\n---\n处理文本时需要将换行符替换为空格，若使用sed命令会比较麻烦，而使用tr命令非常方便。\n\n![](/image/150623/tr-sed-newline.png)\n\n**输入文本(country.txt)**\n```bash\nChina\nAmerica\nFrance\nGerman\n```\n\n**sed命令**(参考[sed命令替换换行符](http://my.oschina.net/shelllife/blog/118337))\n```sh\ncat country.txt | sed ':label;N;s/\\n/ /;b label'\n```\n\n**tr命令**\n```sh\ncat country.txt | tr \"\\n\" \" \"\n```\n\n**两个命令输出一致，但是sed命令的输出结尾有换行符，而tr命令的输出结尾没有换行符**\n```plain\nChina America France German\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：[http://kiwenlau.com/2015/06/23/150623-tr-sed-newline/](http://kiwenlau.com/2015/06/23/150623-tr-sed-newline/)\n***\n","slug":"150623-tr-sed-newline","published":1,"updated":"2015-09-25T07:55:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp85t000b6cv7e54ng8xp"},{"title":"Python截取字符串的子串","date":"2015-06-21T07:31:40.000Z","_content":"\nPython处理字符串非常方便。这篇博客将通过一个简单的示例程序介绍如何使用Python截取字符串的子串。\n\n![](/image/150621/python-substring.png)\n\n**示例程序(example.py):**\n```python\n# coding=utf-8\n\nstr = \"2015-06-21\"\n\nyear = str[0:4]\nmonth = str[5:7]\nday= str[8:10]\n\nprint \"日期: \" + str\nprint \"年: \" + year\nprint \"月: \" + month\nprint \"日: \" + day\n```\n**执行程序：**\n```sh\npython example.py\n```\n**程序输出:**\n```bash\n日期: 2015-06-21\n年: 2015\n月: 06\n日: 21\n```\n**分析：**\n示例程序非常简单，它会截取日期字符串中的年月日。使用子串开始字符与结束字符的偏移量就可以很方便地进行截取。**但是，有两点需要注意**\n\n- 字符串的偏移从0开始。例如，截取\"2015\"时使用str[0:4]而不是str[1:5]。\n- 截取子串时，结束字符是子串最后一个字符的后面一个字符。例如，截取\"2015\"时使用str[0:4]而不是str[0:3]，而“5”的实际偏移量是3。这一点比较容易出现错误。\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/21/150621-python-get-substring/](http://kiwenlau.com/2015/06/21/150621-python-get-substring/)\n***\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/150621-python-get-substring.md","raw":"title: Python截取字符串的子串\n\ndate: 2015-06-21 16:31:40\n\ntags: [Python]\n\n---\n\nPython处理字符串非常方便。这篇博客将通过一个简单的示例程序介绍如何使用Python截取字符串的子串。\n\n![](/image/150621/python-substring.png)\n\n**示例程序(example.py):**\n```python\n# coding=utf-8\n\nstr = \"2015-06-21\"\n\nyear = str[0:4]\nmonth = str[5:7]\nday= str[8:10]\n\nprint \"日期: \" + str\nprint \"年: \" + year\nprint \"月: \" + month\nprint \"日: \" + day\n```\n**执行程序：**\n```sh\npython example.py\n```\n**程序输出:**\n```bash\n日期: 2015-06-21\n年: 2015\n月: 06\n日: 21\n```\n**分析：**\n示例程序非常简单，它会截取日期字符串中的年月日。使用子串开始字符与结束字符的偏移量就可以很方便地进行截取。**但是，有两点需要注意**\n\n- 字符串的偏移从0开始。例如，截取\"2015\"时使用str[0:4]而不是str[1:5]。\n- 截取子串时，结束字符是子串最后一个字符的后面一个字符。例如，截取\"2015\"时使用str[0:4]而不是str[0:3]，而“5”的实际偏移量是3。这一点比较容易出现错误。\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/21/150621-python-get-substring/](http://kiwenlau.com/2015/06/21/150621-python-get-substring/)\n***\n\n\n\n\n\n\n\n\n\n\n\n","slug":"150621-python-get-substring","published":1,"updated":"2015-09-25T07:54:50.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp85y000d6cv7gbfgggmy"},{"title":"ssh-copy-id出错 \"No such file\"","date":"2015-06-20T09:19:40.000Z","_content":"\n[ssh-copy-id](http://manpages.ubuntu.com/manpages/lucid/man1/ssh-copy-id.1.html)命令可以将本地的公钥添加到远程机器的authorized_keys中，从而实现SSH无密码登录。\n\n\n![](/image/150620/ssh-copy-id.png \"ssh-copy-id命令\")\n\n\n在使用ssh-copy-id命令时，出现了如下错误：\n```sh\n$ ssh-copy-id -i id_rsa.pub kiwenlau@136.187.59.2\n/usr/bin/ssh-copy-id: ERROR: failed to open ID file './id_rsa': No such file\n```\n\n命令的输出信息提示没有私钥\"id_rsa\"文件。可知，ssh-copy-id命令执行时将检查公钥id_rsa.pub所在目录是否存在私钥id_rsa，若没有私钥则会导致命令执行失败。\n\n这个问题的解决办法很简单，使用touch命令在公钥id_rsa.pub所在目录下创建一个空文件“id_rsa”即可。\n```sh\n$ touch id_rsa\n```\n\n然后ssh-copy-id命令就可以执行成功了。\n\n```sh\n$ ssh-copy-id -i id_rsa.pub kiwenlau@192.168.59.2\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'kiwenlau@192.168.59.2'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n\n这时，使用ssh登录远程主机将不需要输入密码。\n```sh\n$ ssh kiwenlau@192.168.59.2\nWelcome to Ubuntu 14.04.2 LTS (GNU/Linux 3.13.0-32-generic x86_64)\n\n * Documentation:  https://help.ubuntu.com/\n\n  System information as of Sat Jun 20 15:39:25 JST 2015\n\n  System load:  0.0                Processes:              93\n  Usage of /:   13.0% of 17.34GB   Users logged in:        1\n  Memory usage: 22%                IP address for eth0:    192.168.59.2\n  Swap usage:   0%                 IP address for docker0: 172.17.42.1\n\n  Graph this data and manage this system at:\n    https://landscape.canonical.com/\n\n22 packages can be updated.\n2 updates are security updates.\n\nLast login: Sat Jun 20 15:39:25 2015 from 192.168.59.3\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：[http://kiwenlau.com/2015/06/20/150620-ssh-copy-id-error/](http://kiwenlau.com/2015/06/20/150620-ssh-copy-id-error/)\n***\n\n\n\n\n\n\n\n","source":"_posts/150620-ssh-copy-id-error.md","raw":"title: ssh-copy-id出错 \"No such file\"\n\ndate: 2015-06-20 18:19:40\n\ntags: [Linux]\n\n---\n\n[ssh-copy-id](http://manpages.ubuntu.com/manpages/lucid/man1/ssh-copy-id.1.html)命令可以将本地的公钥添加到远程机器的authorized_keys中，从而实现SSH无密码登录。\n\n\n![](/image/150620/ssh-copy-id.png \"ssh-copy-id命令\")\n\n\n在使用ssh-copy-id命令时，出现了如下错误：\n```sh\n$ ssh-copy-id -i id_rsa.pub kiwenlau@136.187.59.2\n/usr/bin/ssh-copy-id: ERROR: failed to open ID file './id_rsa': No such file\n```\n\n命令的输出信息提示没有私钥\"id_rsa\"文件。可知，ssh-copy-id命令执行时将检查公钥id_rsa.pub所在目录是否存在私钥id_rsa，若没有私钥则会导致命令执行失败。\n\n这个问题的解决办法很简单，使用touch命令在公钥id_rsa.pub所在目录下创建一个空文件“id_rsa”即可。\n```sh\n$ touch id_rsa\n```\n\n然后ssh-copy-id命令就可以执行成功了。\n\n```sh\n$ ssh-copy-id -i id_rsa.pub kiwenlau@192.168.59.2\n/usr/bin/ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed\n/usr/bin/ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys\n\nNumber of key(s) added: 1\n\nNow try logging into the machine, with:   \"ssh 'kiwenlau@192.168.59.2'\"\nand check to make sure that only the key(s) you wanted were added.\n```\n\n这时，使用ssh登录远程主机将不需要输入密码。\n```sh\n$ ssh kiwenlau@192.168.59.2\nWelcome to Ubuntu 14.04.2 LTS (GNU/Linux 3.13.0-32-generic x86_64)\n\n * Documentation:  https://help.ubuntu.com/\n\n  System information as of Sat Jun 20 15:39:25 JST 2015\n\n  System load:  0.0                Processes:              93\n  Usage of /:   13.0% of 17.34GB   Users logged in:        1\n  Memory usage: 22%                IP address for eth0:    192.168.59.2\n  Swap usage:   0%                 IP address for docker0: 172.17.42.1\n\n  Graph this data and manage this system at:\n    https://landscape.canonical.com/\n\n22 packages can be updated.\n2 updates are security updates.\n\nLast login: Sat Jun 20 15:39:25 2015 from 192.168.59.3\n```\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：[http://kiwenlau.com/2015/06/20/150620-ssh-copy-id-error/](http://kiwenlau.com/2015/06/20/150620-ssh-copy-id-error/)\n***\n\n\n\n\n\n\n\n","slug":"150620-ssh-copy-id-error","published":1,"updated":"2015-09-18T05:39:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp864000g6cv76ql9130h"},{"title":"基于Docker快速搭建多节点Hadopp集群","date":"2015-06-08T03:44:40.000Z","_content":"\nGitHub: [kiwenlau/hadoop-cluster-docker](https://github.com/kiwenlau)\n\n可以直接进入第三部分，快速在本机搭建一个3个节点的Hadoop集群\n\n\n##一. 项目简介\n\n直接用机器搭建Hadoop集群是一个相当痛苦的过程，尤其对初学者来说。他们还没开始跑wordcount，可能就被这个问题折腾的体无完肤了。\n\n我的目标是将Hadoop集群运行在Docker容器中，使Hadoop开发者能够快速便捷地在本机搭建多节点的Hadoop集群。其实这个想法已经有了不少实现，但是都不是很理想，他们或者镜像太大，或者使用太慢，或者使用了第三方工具使得使用起来过于复杂...下表为一些已知的Hadoop on Docker项目以及其存在的问题。\n\n\n|                  项目                             | 镜像大小    |        问题                        |\n| : ------------- ---------------| : ------ | :-------------------- |\n|sequenceiq/hadoop-docker:latest  |1.491GB    | 镜像太大，只支持单个节点|\n|sequenceiq/hadoop-docker:2.7.0  |1.76 GB     |           同上                           |\n|sequenceiq/hadoop-docker:2.6.0  |1.624GB    |         同上                            |\n|sequenceiq/ambari:latest               |1.782GB     |  镜像太大，使用太慢|\n|sequenceiq/ambari:2.0.0               |4.804GB     |          同上                           |\n|sequenceiq/ambari:latest:1.70      |4.761GB    |         同上                         |\n|alvinhenrick/hadoop-mutinode     |4.331GB    |镜像太大，构建太慢，增加节点麻烦，有bug\n\n我的项目参考了alvinhenrick/hadoop-mutinode项目，不过我做了大量的优化和重构。alvinhenrick/hadoop-mutinode项目的Github主页以及作者所写的博客地址：[GitHub](https://github.com/alvinhenrick/hadoop-mutinode)，[博客](http://alvinhenrick.com/2014/07/16/hadoop-yarn-multinode-cluster-with-docker/)\n\n下面两个表是alvinhenrick/hadoop-mutinode项目与我的kiwenlau/hadoop-cluster-docker项目的参数对比\n\n|镜像名称\t                                 |构建时间\t       | 镜像层数   | 镜像大小 |\n| :-------------------------| :---------- | :------- | :------- |\n|alvinhenrick/serf                     |258.213s       | 21\t        | 239.4MB |\n|alvinhenrick/hadoop-base\t| 2236.055s    | 58\t        | 4.328GB |\n|alvinhenrick/hadoop-dn\t        | 51.959s        | 74\t        | 4.331GB |\n|alvinhenrick/hadoop-nn-dn    | 49.548s       |  84           | 4.331GB |\n\n|镜像名称\t                                 |构建时间\t       | 镜像层数   | 镜像大小 |\n| :-------------------------| :---------- | :------- | :------- |\n| kiwenlau/serf-dnsmasq          | 509.46s        |  8\t        | 206.6 MB |\n|kiwenlau/hadoop-base\t         | 400.29s\t        |  7\t        | 775.4 MB |\n|kiwenlau/hadoop-master         | 5.41s            |  9\t        | 775.4 MB |\n|kiwenlau/hadoop-slave\t         | 2.41s\t        |  8 \t        | 775.4 MB |\n\n可知，我主要优化了这样几点\n- 更小的镜像大小\n- 更快的构造时间\n- 更少的镜像层数\n\n####更快更方便地改变Hadoop集群节点数目\n\n另外，alvinhenrick/hadoop-mutinode项目增加节点时需要手动修改Hadoop配置文件然后重新构建hadoop-nn-dn镜像,然后修改容器启动脚本，才能实现增加节点的功能。而我通过shell脚本实现自动话，不到1分钟可以重新构建hadoop-master镜像，然后立即运行！！！本项目默认启动3个节点的Hadoop集群，支持任意节点数的hadoop集群。\n\n另外，启动hadoop, 运行wordcount以及重新构建镜像都采用了shell脚本实现自动化。这样使得整个项目的使用以及开发都变得非常方便快捷:)\n\n####开发测试环境\n\n- 操作系统：ubuntu 14.04 和 ubuntu 12.04\n- 内核版本: 3.13.0-32-generic\n- Docker版本：1.5.0 和1.6.2\n\n####硬盘不够，内存不够，尤其是内核版本过低会导致运行失败:(\n\n##二. 镜像简介\n\n###本项目一共开发了4个镜像\n\n- serf-dnsmasq\n- hadoop-base\n- hadoop-master\n- hadoop-slave\n\n###serf-dnsmasq镜像\n\n- 基于ubuntu:15.04 (选它是因为它最小，不是因为它最新...)\n- 安装serf: serf是一个分布式的机器节点管理工具。它可以动态地发现所有hadoop集群节点。\n- 安装dnsmasq: dnsmasq作为轻量级的dns服务器。它可以为hadoop集群提供域名解析服务。\n\n容器启动时，master节点的IP会传给所有slave节点。serf会在container启动后立即启动。slave节点上的serf agent会马上发现master节点（master IP它们都知道嘛），master节点就马上发现了所有slave节点。然后它们之间通过互相交换信息，所有节点就能知道其他所有节点的存在了！(Everyone will know Everyone). serf发现新的节点时，就会重新配置dnsmasq,然后重启dnsmasq. 所以dnsmasq就能够解析集群的所有节点的域名啦。这个过程随着节点的增加会耗时更久，因此，若配置的Hadoop节点比较多，则在启动容器后需要测试serf是否发现了所有节点，dns是否能够解析所有节点域名。稍等片刻才能启动Hadoop。这个解决方案是由SequenceIQ公司提出的，该公司专注于将Hadoop运行在Docker中。请参考这个PPT：[Docker-based Hadoop Provisioning](http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning)\n\n###hadoop-base镜像\n\n- 基于serf-dnsmasq镜像\n- 安装JDK(openjdk)\n- 安装openssh-server, 配置无密码ssh\n- 安装vim：介样就可以愉快地在容器中敲代码了:)\n- 安装Hadoop 2.3.0: 安装编译过的hadoop （2.5.2， 2.6.0， 2.7.0 都比2.3.0大，所以我懒得升级了）\n\n编译Hadoop的步骤请参考我的博客：[[Hadoop 2.30 在Ubuntu 14.04 中编译](http://www.cnblogs.com/kiwenlau/p/4227204.html)](http://www.cnblogs.com/kiwenlau/p/4227204.html)\n\n如果需要重新开发我的hadoop-base, 需要下载编译过的hadoop-2.3.0安装包，放到hadoop-cluster-docker/hadoop-base/files目录内。我编译的64位hadoop-2.3.0下载地址：[hadoop-2.3.0](http://pan.baidu.com/s/1sjFRaFz)\n\n另外，我还编译了64位的hadoop 2.5.2, 2.6.0, 2.7.0, 其下载地址如下：\n\n- [hadoop-2.3.0](http://pan.baidu.com/s/1sjFRaFz)\n- [hadoop-2.5.2](http://pan.baidu.com/s/1jGw24aa)\n- [hadoop-2.6.0](http://pan.baidu.com/s/1eQgvF2M)\n- [hadoop-2.7.0]( http://pan.baidu.com/s/1c0HD0Nu)\n\n###hadoop-master镜像\n\n- 基于hadoop-base镜像\n- 配置hadoop的master节点\n- 格式化namenode\n\n这一步需要配置slaves文件，而slaves文件需要列出所有节点的域名或者IP。因此，Hadoop节点数目不同时，slaves文件自然也不一样。因此，更改Hadoop集群节点数目时，需要修改slaves文件然后重新构建hadoop-master镜像。我编写了一个resize-cluster.sh脚本自动化这一过程。仅需给定节点数目作为脚本参数就可以轻松实现Hadoop集群节点数目的更改。由于hadoop-master镜像仅仅做一些配置工作，也无需下载任何文件，整个过程非常快，1分钟就足够了。\n\n###hadoop-slave镜像\n\n- 基于hadoop-base镜像\n- 配置hadoop的slave节点\n\n###镜像大小分析\n\n下表为sudo docker images的运行结果\n\n|REPOSITORY       |   TAG    |  IMAGE ID       | CREATED     |   VIRTUAL SIZE |\n| ------------- | ------- | ---------- | ---------- | ------- |\n|index.alauda.cn/kiwenlau/hadoop-slave   | 0.1.0|    d63869855c03 |   17 hours ago  |  777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-master|    0.1.0   | 7c9d32ede450  |  17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-base  |    0.1.0   | 5571bd5de58e    |17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/serf-dnsmasq  |  0.1.0    |09ed89c24ee8   | 17 hours ago  |  206.7 MB |\n|ubuntu     |                               15.04   | bd94ae587483  |  3 weeks ago    |131.3 MB |\n\n\n易知以下几个结论：\n- serf-dnsmasq镜像在ubuntu:15.04镜像的基础上增加了75.4MB\n- hadoop-base镜像在serf-dnsmasq镜像的基础上增加了570.7MB\n- hadoop-master和hadoop-slave镜像在hadoop-base镜像的基础上大小几乎没有增加\n\n下表为docker history index.alauda.cn/kiwenlau/hadoop-base:0.1.0命令的部分运行结果\n\n|IMAGE      |    CREATED        |    CREATED BY         |                             SIZE\n |  -----  | ---------------  | ---------------  |  -----------  | \n|2039b9b81146 |   44 hours ago   |       /bin/sh -c #(nop) ADD   multi:a93c971a49514e787  |  158.5 MB | \n | cdb620312f30    |  44 hours ago   |       /bin/sh -c apt-get install -y openjdk-7-jdk    |  324.6 MB  | \n | da7d10c790c1   |   44 hours ago      |    /bin/sh -c apt-get install -y openssh-server   |   87.58 MB  | \n |  c65cb568defc    |  44 hours ago     |     /bin/sh -c curl -Lso serf.zip https://dl.bint  |  14.46 MB  | \n | 3e22b3d72e33     | 44 hours ago       |   /bin/sh -c apt-get update && apt-get install     |  60.89 MB   | \n |  b68f8c8d2140    |  3 weeks ago     |     /bin/sh -c #(nop) ADD file:d90f7467c470bfa9a3  |   131.3 MB  | \n\n可知\n- 基础镜像ubuntu:15.04为131.3MB\n- 安装openjdk需要324.6MB\n- 安装hadoop需要158.5MB\n- ubuntu,openjdk与hadoop均为镜像所必须，三者一共占了:614.4MB\n\n### 因此，我所开发的hadoop镜像以及接近最小，优化空间已经很小了\n\n下图显示了项目的Docker镜像结构：\n\n![](/image/150608/image architecture.jpg \"Image Architecture\")\n\n##三. 3节点Hadoop集群搭建步骤\n\n###1. 拉取镜像\n\n```sh\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-master:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-slave:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-base:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/serf-dnsmasq:0.1.0\n```\n\n- 3~5分钟OK~\n\n*查看下载的镜像*\n\n```sh\nsudo docker images\n```\n\n*运行结果*\n\n|REPOSITORY    |    TAG  |    IMAGE ID      |  CREATED  |      VIRTUAL SIZE |\n |  ----------  |  -----------  |  ---------  |   --------  |  \n| index.alauda.cn/kiwenlau/hadoop-slave   | 0.1.0    |d63869855c03  |  17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-master   |   0.1.0 |     7c9d32ede450   |   17 hours ago  |    777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-base |       0.1.0     | 5571bd5de58e   |   17 hours ago  |    777.4 MB | \n |  index.alauda.cn/kiwenlau/serf-dnsmasq   |   0.1.0   |   09ed89c24ee8     | 17 hours ago     |  206.7 MB | \n\n- hadoop-base镜像是基于serf-dnsmasq镜像的，hadoop-slave镜像和hadoop-master镜像都是基于hadoop-base镜像\n- 所以其实4个镜像一共也就777.4MB:)\n\n###2. 修改镜像tag\n\n```sh\nsudo docker tag d63869855c03 kiwenlau/hadoop-slave:0.1.0\nsudo docker tag 7c9d32ede450 kiwenlau/hadoop-master:0.1.0\nsudo docker tag 5571bd5de58e kiwenlau/hadoop-base:0.1.0\nsudo docker tag 09ed89c24ee8 kiwenlau/serf-dnsmasq:0.1.0\n```\n\n*查看修改tag后镜像*\n\n```sh\nsudo docker images\n```\n\n*运行结果*\n\n| REPOSITORY   |   TAG   |    IMAGE ID    |    CREATED    |      VIRTUAL SIZE  | \n |  ----------  |  -----  |  ---------  |  ----------  |  -----------  | \n| index.alauda.cn/kiwenlau/hadoop-slave  |    0.1.0   |   d63869855c03    |  17 hours ago   |   777.4 MB\n | kiwenlau/hadoop-slave    |                  0.1.0   |   d63869855c03   |   17 hours ago  |    777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-master  |  0.1.0 |     7c9d32ede450   |   17 hours ago |     777.4 MB | \n | kiwenlau/hadoop-master  |                  0.1.0   |   7c9d32ede450   |   17 hours ago |     777.4 MB | \n | kiwenlau/hadoop-base   |                   0.1.0  |    5571bd5de58e  |    17 hours ago   |   777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-base  |    0.1.0   |   5571bd5de58e   |   17 hours ago |     777.4 MB | \n | kiwenlau/serf-dnsmasq          |            0.1.0    |  09ed89c24ee8  |    17 hours ago    |  206.7 MB | \n | index.alauda.cn/kiwenlau/serf-dnsmasq  |    0.1.0   |   09ed89c24ee8     | 17 hours ago   |   206.7 MB | \n\n- 之所以要修改镜像，是因为我默认是将镜像上传到Dockerhub, 因此Dokerfile以及shell脚本中得镜像名称都是没有alauada前缀的，sorry for this....不过改tag还是很快滴\n- 若直接下载我在DockerHub中的镜像，自然就不需要修改tag...不过Alauda镜像下载速度很快的哈~\n\n###3.下载源代码\n\n```sh\ngit clone https://github.com/kiwenlau/hadoop-cluster-docker\n```\n\n- 为了防止Github被XX, 我把代码导入到了开源中国的git仓库\n\n```sh\ngit clone http://git.oschina.net/kiwenlau/hadoop-cluster-docker\n```\n\n###4. 运行容器\n\n```sh\ncd hadoop-cluster-docker\n./start-container.sh\n\n```\n\n*运行结果*\n\n```bash\nstart master container...\nstart slave1 container...\nstart slave2 container...\nroot@master:~#\n```\n\n- 一共开启了3个容器，1个master, 2个slave\n- 开启容器后就进入了master容器root用户的家目录（/root）\n\n*查看master的root用户家目录的文件*\n\n```sh\nls\n```\n\n*运行结果*\n\n```plain\nhdfs  run-wordcount.sh\tserf_log  start-hadoop.sh  start-ssh-serf.sh\n```\n\n- start-hadoop.sh是开启hadoop的shell脚本\n- run-wordcount.sh是运行wordcount的shell脚本，可以测试镜像是否正常工作\n\n###5.测试容器是否正常启动(此时已进入master容器)\n\n*查看hadoop集群成员*\n\n```sh\nserf members\n```\n\n*运行结果*\n\n```bash\nmaster.kiwenlau.com  172.17.0.65:7946  alive\nslave1.kiwenlau.com  172.17.0.66:7946  alive\nslave2.kiwenlau.com  172.17.0.67:7946  alive\n```\n\n- 若结果缺少节点，可以稍等片刻，再执行“serf members”命令。因为serf agent需要时间发现所有节点。\n\n*测试ssh*\n\n```sh\nssh slave2.kiwenlau.com\n```\n\n*运行结果*\n\n```bash\nWarning: Permanently added 'slave2.kiwenlau.com,172.17.0.67' (ECDSA) to the list of known hosts.\nWelcome to Ubuntu 15.04 (GNU/Linux 3.13.0-53-generic x86_64)\n* Documentation:  https://help.ubuntu.com/\nThe programs included with the Ubuntu system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\nroot@slave2:~#\n```\n\n*退出slave2*\n\n```sh\nexit\n```\n\n*运行结果*\n\n```bash\nlogout\nConnection to slave2.kiwenlau.com closed.\n```\n\n- 若ssh失败，请稍等片刻再测试，因为dnsmasq的dns服务器启动需要时间。\n- 测试成功后，就可以开启Hadoop集群了！其实你也可以不进行测试，开启容器后耐心等待一分钟即可！\n\n###6. 开启hadoop\n\n```sh\n./start-hadoop.sh\n```\n\n- 上一步ssh到slave2之后，请记得回到master啊!!！\n- 运行结果太多，忽略....\n- hadoop的启动速度取决于机器性能....\n\n###7. 运行wordcount\n\n```sh\n./run-wordcount.sh\n```\n\n*运行结果*\n```bash\ninput file1.txt:\nHello Hadoop\ninput file2.txt:\nHello Docker\nwordcount output:\nDocker\t1\nHadoop\t1\nHello\t2\n```\n\n- wordcount的执行速度取决于机器性能....\n\n##四. N节点Hadoop集群搭建步骤\n\n###1. 准备工作\n\n- 参考第二部分1~3：下载镜像，修改tag，下载源代码\n- 注意，你可以不下载serf-dnsmasq, 但是请最好下载hadoop-base，因为hadoop-master是基于hadoop-base构建的\n\n###2. 重新构建hadoop-master镜像\n\n```sh\n./resize-cluster.sh 5\n```\n\n- 不要担心，1分钟就能搞定\n- 你可以为resize-cluster.sh脚本设不同的正整数作为参数数1, 2, 3, 4, 5, 6...\n\n###3. 启动容器\n\n```sh\n./start-container.sh 5\n```\n\n- 你可以为resize-cluster.sh脚本设不同的正整数作为参数数1, 2, 3, 4, 5, 6...\n- 这个参数呢，最好还是得和上一步的参数一致:)\n- 这个参数如果比上一步的参数大，你多启动的节点，Hadoop不认识它们..\n- 这个参数如果比上一步的参数小，Hadoop觉得少启动的节点挂掉了..\n\n###4. 测试工作\n\n- 参考第三部分5~7：测试容器，开启Hadoop，运行wordcount\n- 请注意，若节点增加，请务必先测试容器，然后再开启Hadoop, 因为serf可能还没有发现所有节点，而dnsmasq的DNS服务器表示还没有配置好服务\n- 测试等待时间取决于机器性能....\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/08/150608-hadoop-cluster-docker/](http://kiwenlau.com/2015/06/08/150608-hadoop-cluster-docker/)\n***","source":"_posts/150608-hadoop-cluster-docker.md","raw":"title: 基于Docker快速搭建多节点Hadopp集群\n\ndate: 2015-06-08 12:44:40\n\ntags: [Hadoop, Docker]\n\n---\n\nGitHub: [kiwenlau/hadoop-cluster-docker](https://github.com/kiwenlau)\n\n可以直接进入第三部分，快速在本机搭建一个3个节点的Hadoop集群\n\n\n##一. 项目简介\n\n直接用机器搭建Hadoop集群是一个相当痛苦的过程，尤其对初学者来说。他们还没开始跑wordcount，可能就被这个问题折腾的体无完肤了。\n\n我的目标是将Hadoop集群运行在Docker容器中，使Hadoop开发者能够快速便捷地在本机搭建多节点的Hadoop集群。其实这个想法已经有了不少实现，但是都不是很理想，他们或者镜像太大，或者使用太慢，或者使用了第三方工具使得使用起来过于复杂...下表为一些已知的Hadoop on Docker项目以及其存在的问题。\n\n\n|                  项目                             | 镜像大小    |        问题                        |\n| : ------------- ---------------| : ------ | :-------------------- |\n|sequenceiq/hadoop-docker:latest  |1.491GB    | 镜像太大，只支持单个节点|\n|sequenceiq/hadoop-docker:2.7.0  |1.76 GB     |           同上                           |\n|sequenceiq/hadoop-docker:2.6.0  |1.624GB    |         同上                            |\n|sequenceiq/ambari:latest               |1.782GB     |  镜像太大，使用太慢|\n|sequenceiq/ambari:2.0.0               |4.804GB     |          同上                           |\n|sequenceiq/ambari:latest:1.70      |4.761GB    |         同上                         |\n|alvinhenrick/hadoop-mutinode     |4.331GB    |镜像太大，构建太慢，增加节点麻烦，有bug\n\n我的项目参考了alvinhenrick/hadoop-mutinode项目，不过我做了大量的优化和重构。alvinhenrick/hadoop-mutinode项目的Github主页以及作者所写的博客地址：[GitHub](https://github.com/alvinhenrick/hadoop-mutinode)，[博客](http://alvinhenrick.com/2014/07/16/hadoop-yarn-multinode-cluster-with-docker/)\n\n下面两个表是alvinhenrick/hadoop-mutinode项目与我的kiwenlau/hadoop-cluster-docker项目的参数对比\n\n|镜像名称\t                                 |构建时间\t       | 镜像层数   | 镜像大小 |\n| :-------------------------| :---------- | :------- | :------- |\n|alvinhenrick/serf                     |258.213s       | 21\t        | 239.4MB |\n|alvinhenrick/hadoop-base\t| 2236.055s    | 58\t        | 4.328GB |\n|alvinhenrick/hadoop-dn\t        | 51.959s        | 74\t        | 4.331GB |\n|alvinhenrick/hadoop-nn-dn    | 49.548s       |  84           | 4.331GB |\n\n|镜像名称\t                                 |构建时间\t       | 镜像层数   | 镜像大小 |\n| :-------------------------| :---------- | :------- | :------- |\n| kiwenlau/serf-dnsmasq          | 509.46s        |  8\t        | 206.6 MB |\n|kiwenlau/hadoop-base\t         | 400.29s\t        |  7\t        | 775.4 MB |\n|kiwenlau/hadoop-master         | 5.41s            |  9\t        | 775.4 MB |\n|kiwenlau/hadoop-slave\t         | 2.41s\t        |  8 \t        | 775.4 MB |\n\n可知，我主要优化了这样几点\n- 更小的镜像大小\n- 更快的构造时间\n- 更少的镜像层数\n\n####更快更方便地改变Hadoop集群节点数目\n\n另外，alvinhenrick/hadoop-mutinode项目增加节点时需要手动修改Hadoop配置文件然后重新构建hadoop-nn-dn镜像,然后修改容器启动脚本，才能实现增加节点的功能。而我通过shell脚本实现自动话，不到1分钟可以重新构建hadoop-master镜像，然后立即运行！！！本项目默认启动3个节点的Hadoop集群，支持任意节点数的hadoop集群。\n\n另外，启动hadoop, 运行wordcount以及重新构建镜像都采用了shell脚本实现自动化。这样使得整个项目的使用以及开发都变得非常方便快捷:)\n\n####开发测试环境\n\n- 操作系统：ubuntu 14.04 和 ubuntu 12.04\n- 内核版本: 3.13.0-32-generic\n- Docker版本：1.5.0 和1.6.2\n\n####硬盘不够，内存不够，尤其是内核版本过低会导致运行失败:(\n\n##二. 镜像简介\n\n###本项目一共开发了4个镜像\n\n- serf-dnsmasq\n- hadoop-base\n- hadoop-master\n- hadoop-slave\n\n###serf-dnsmasq镜像\n\n- 基于ubuntu:15.04 (选它是因为它最小，不是因为它最新...)\n- 安装serf: serf是一个分布式的机器节点管理工具。它可以动态地发现所有hadoop集群节点。\n- 安装dnsmasq: dnsmasq作为轻量级的dns服务器。它可以为hadoop集群提供域名解析服务。\n\n容器启动时，master节点的IP会传给所有slave节点。serf会在container启动后立即启动。slave节点上的serf agent会马上发现master节点（master IP它们都知道嘛），master节点就马上发现了所有slave节点。然后它们之间通过互相交换信息，所有节点就能知道其他所有节点的存在了！(Everyone will know Everyone). serf发现新的节点时，就会重新配置dnsmasq,然后重启dnsmasq. 所以dnsmasq就能够解析集群的所有节点的域名啦。这个过程随着节点的增加会耗时更久，因此，若配置的Hadoop节点比较多，则在启动容器后需要测试serf是否发现了所有节点，dns是否能够解析所有节点域名。稍等片刻才能启动Hadoop。这个解决方案是由SequenceIQ公司提出的，该公司专注于将Hadoop运行在Docker中。请参考这个PPT：[Docker-based Hadoop Provisioning](http://www.slideshare.net/JanosMatyas/docker-based-hadoop-provisioning)\n\n###hadoop-base镜像\n\n- 基于serf-dnsmasq镜像\n- 安装JDK(openjdk)\n- 安装openssh-server, 配置无密码ssh\n- 安装vim：介样就可以愉快地在容器中敲代码了:)\n- 安装Hadoop 2.3.0: 安装编译过的hadoop （2.5.2， 2.6.0， 2.7.0 都比2.3.0大，所以我懒得升级了）\n\n编译Hadoop的步骤请参考我的博客：[[Hadoop 2.30 在Ubuntu 14.04 中编译](http://www.cnblogs.com/kiwenlau/p/4227204.html)](http://www.cnblogs.com/kiwenlau/p/4227204.html)\n\n如果需要重新开发我的hadoop-base, 需要下载编译过的hadoop-2.3.0安装包，放到hadoop-cluster-docker/hadoop-base/files目录内。我编译的64位hadoop-2.3.0下载地址：[hadoop-2.3.0](http://pan.baidu.com/s/1sjFRaFz)\n\n另外，我还编译了64位的hadoop 2.5.2, 2.6.0, 2.7.0, 其下载地址如下：\n\n- [hadoop-2.3.0](http://pan.baidu.com/s/1sjFRaFz)\n- [hadoop-2.5.2](http://pan.baidu.com/s/1jGw24aa)\n- [hadoop-2.6.0](http://pan.baidu.com/s/1eQgvF2M)\n- [hadoop-2.7.0]( http://pan.baidu.com/s/1c0HD0Nu)\n\n###hadoop-master镜像\n\n- 基于hadoop-base镜像\n- 配置hadoop的master节点\n- 格式化namenode\n\n这一步需要配置slaves文件，而slaves文件需要列出所有节点的域名或者IP。因此，Hadoop节点数目不同时，slaves文件自然也不一样。因此，更改Hadoop集群节点数目时，需要修改slaves文件然后重新构建hadoop-master镜像。我编写了一个resize-cluster.sh脚本自动化这一过程。仅需给定节点数目作为脚本参数就可以轻松实现Hadoop集群节点数目的更改。由于hadoop-master镜像仅仅做一些配置工作，也无需下载任何文件，整个过程非常快，1分钟就足够了。\n\n###hadoop-slave镜像\n\n- 基于hadoop-base镜像\n- 配置hadoop的slave节点\n\n###镜像大小分析\n\n下表为sudo docker images的运行结果\n\n|REPOSITORY       |   TAG    |  IMAGE ID       | CREATED     |   VIRTUAL SIZE |\n| ------------- | ------- | ---------- | ---------- | ------- |\n|index.alauda.cn/kiwenlau/hadoop-slave   | 0.1.0|    d63869855c03 |   17 hours ago  |  777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-master|    0.1.0   | 7c9d32ede450  |  17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-base  |    0.1.0   | 5571bd5de58e    |17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/serf-dnsmasq  |  0.1.0    |09ed89c24ee8   | 17 hours ago  |  206.7 MB |\n|ubuntu     |                               15.04   | bd94ae587483  |  3 weeks ago    |131.3 MB |\n\n\n易知以下几个结论：\n- serf-dnsmasq镜像在ubuntu:15.04镜像的基础上增加了75.4MB\n- hadoop-base镜像在serf-dnsmasq镜像的基础上增加了570.7MB\n- hadoop-master和hadoop-slave镜像在hadoop-base镜像的基础上大小几乎没有增加\n\n下表为docker history index.alauda.cn/kiwenlau/hadoop-base:0.1.0命令的部分运行结果\n\n|IMAGE      |    CREATED        |    CREATED BY         |                             SIZE\n |  -----  | ---------------  | ---------------  |  -----------  | \n|2039b9b81146 |   44 hours ago   |       /bin/sh -c #(nop) ADD   multi:a93c971a49514e787  |  158.5 MB | \n | cdb620312f30    |  44 hours ago   |       /bin/sh -c apt-get install -y openjdk-7-jdk    |  324.6 MB  | \n | da7d10c790c1   |   44 hours ago      |    /bin/sh -c apt-get install -y openssh-server   |   87.58 MB  | \n |  c65cb568defc    |  44 hours ago     |     /bin/sh -c curl -Lso serf.zip https://dl.bint  |  14.46 MB  | \n | 3e22b3d72e33     | 44 hours ago       |   /bin/sh -c apt-get update && apt-get install     |  60.89 MB   | \n |  b68f8c8d2140    |  3 weeks ago     |     /bin/sh -c #(nop) ADD file:d90f7467c470bfa9a3  |   131.3 MB  | \n\n可知\n- 基础镜像ubuntu:15.04为131.3MB\n- 安装openjdk需要324.6MB\n- 安装hadoop需要158.5MB\n- ubuntu,openjdk与hadoop均为镜像所必须，三者一共占了:614.4MB\n\n### 因此，我所开发的hadoop镜像以及接近最小，优化空间已经很小了\n\n下图显示了项目的Docker镜像结构：\n\n![](/image/150608/image architecture.jpg \"Image Architecture\")\n\n##三. 3节点Hadoop集群搭建步骤\n\n###1. 拉取镜像\n\n```sh\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-master:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-slave:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/hadoop-base:0.1.0\nsudo docker pull index.alauda.cn/kiwenlau/serf-dnsmasq:0.1.0\n```\n\n- 3~5分钟OK~\n\n*查看下载的镜像*\n\n```sh\nsudo docker images\n```\n\n*运行结果*\n\n|REPOSITORY    |    TAG  |    IMAGE ID      |  CREATED  |      VIRTUAL SIZE |\n |  ----------  |  -----------  |  ---------  |   --------  |  \n| index.alauda.cn/kiwenlau/hadoop-slave   | 0.1.0    |d63869855c03  |  17 hours ago   | 777.4 MB|\n|index.alauda.cn/kiwenlau/hadoop-master   |   0.1.0 |     7c9d32ede450   |   17 hours ago  |    777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-base |       0.1.0     | 5571bd5de58e   |   17 hours ago  |    777.4 MB | \n |  index.alauda.cn/kiwenlau/serf-dnsmasq   |   0.1.0   |   09ed89c24ee8     | 17 hours ago     |  206.7 MB | \n\n- hadoop-base镜像是基于serf-dnsmasq镜像的，hadoop-slave镜像和hadoop-master镜像都是基于hadoop-base镜像\n- 所以其实4个镜像一共也就777.4MB:)\n\n###2. 修改镜像tag\n\n```sh\nsudo docker tag d63869855c03 kiwenlau/hadoop-slave:0.1.0\nsudo docker tag 7c9d32ede450 kiwenlau/hadoop-master:0.1.0\nsudo docker tag 5571bd5de58e kiwenlau/hadoop-base:0.1.0\nsudo docker tag 09ed89c24ee8 kiwenlau/serf-dnsmasq:0.1.0\n```\n\n*查看修改tag后镜像*\n\n```sh\nsudo docker images\n```\n\n*运行结果*\n\n| REPOSITORY   |   TAG   |    IMAGE ID    |    CREATED    |      VIRTUAL SIZE  | \n |  ----------  |  -----  |  ---------  |  ----------  |  -----------  | \n| index.alauda.cn/kiwenlau/hadoop-slave  |    0.1.0   |   d63869855c03    |  17 hours ago   |   777.4 MB\n | kiwenlau/hadoop-slave    |                  0.1.0   |   d63869855c03   |   17 hours ago  |    777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-master  |  0.1.0 |     7c9d32ede450   |   17 hours ago |     777.4 MB | \n | kiwenlau/hadoop-master  |                  0.1.0   |   7c9d32ede450   |   17 hours ago |     777.4 MB | \n | kiwenlau/hadoop-base   |                   0.1.0  |    5571bd5de58e  |    17 hours ago   |   777.4 MB | \n | index.alauda.cn/kiwenlau/hadoop-base  |    0.1.0   |   5571bd5de58e   |   17 hours ago |     777.4 MB | \n | kiwenlau/serf-dnsmasq          |            0.1.0    |  09ed89c24ee8  |    17 hours ago    |  206.7 MB | \n | index.alauda.cn/kiwenlau/serf-dnsmasq  |    0.1.0   |   09ed89c24ee8     | 17 hours ago   |   206.7 MB | \n\n- 之所以要修改镜像，是因为我默认是将镜像上传到Dockerhub, 因此Dokerfile以及shell脚本中得镜像名称都是没有alauada前缀的，sorry for this....不过改tag还是很快滴\n- 若直接下载我在DockerHub中的镜像，自然就不需要修改tag...不过Alauda镜像下载速度很快的哈~\n\n###3.下载源代码\n\n```sh\ngit clone https://github.com/kiwenlau/hadoop-cluster-docker\n```\n\n- 为了防止Github被XX, 我把代码导入到了开源中国的git仓库\n\n```sh\ngit clone http://git.oschina.net/kiwenlau/hadoop-cluster-docker\n```\n\n###4. 运行容器\n\n```sh\ncd hadoop-cluster-docker\n./start-container.sh\n\n```\n\n*运行结果*\n\n```bash\nstart master container...\nstart slave1 container...\nstart slave2 container...\nroot@master:~#\n```\n\n- 一共开启了3个容器，1个master, 2个slave\n- 开启容器后就进入了master容器root用户的家目录（/root）\n\n*查看master的root用户家目录的文件*\n\n```sh\nls\n```\n\n*运行结果*\n\n```plain\nhdfs  run-wordcount.sh\tserf_log  start-hadoop.sh  start-ssh-serf.sh\n```\n\n- start-hadoop.sh是开启hadoop的shell脚本\n- run-wordcount.sh是运行wordcount的shell脚本，可以测试镜像是否正常工作\n\n###5.测试容器是否正常启动(此时已进入master容器)\n\n*查看hadoop集群成员*\n\n```sh\nserf members\n```\n\n*运行结果*\n\n```bash\nmaster.kiwenlau.com  172.17.0.65:7946  alive\nslave1.kiwenlau.com  172.17.0.66:7946  alive\nslave2.kiwenlau.com  172.17.0.67:7946  alive\n```\n\n- 若结果缺少节点，可以稍等片刻，再执行“serf members”命令。因为serf agent需要时间发现所有节点。\n\n*测试ssh*\n\n```sh\nssh slave2.kiwenlau.com\n```\n\n*运行结果*\n\n```bash\nWarning: Permanently added 'slave2.kiwenlau.com,172.17.0.67' (ECDSA) to the list of known hosts.\nWelcome to Ubuntu 15.04 (GNU/Linux 3.13.0-53-generic x86_64)\n* Documentation:  https://help.ubuntu.com/\nThe programs included with the Ubuntu system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\nUbuntu comes with ABSOLUTELY NO WARRANTY, to the extent permitted by\napplicable law.\nroot@slave2:~#\n```\n\n*退出slave2*\n\n```sh\nexit\n```\n\n*运行结果*\n\n```bash\nlogout\nConnection to slave2.kiwenlau.com closed.\n```\n\n- 若ssh失败，请稍等片刻再测试，因为dnsmasq的dns服务器启动需要时间。\n- 测试成功后，就可以开启Hadoop集群了！其实你也可以不进行测试，开启容器后耐心等待一分钟即可！\n\n###6. 开启hadoop\n\n```sh\n./start-hadoop.sh\n```\n\n- 上一步ssh到slave2之后，请记得回到master啊!!！\n- 运行结果太多，忽略....\n- hadoop的启动速度取决于机器性能....\n\n###7. 运行wordcount\n\n```sh\n./run-wordcount.sh\n```\n\n*运行结果*\n```bash\ninput file1.txt:\nHello Hadoop\ninput file2.txt:\nHello Docker\nwordcount output:\nDocker\t1\nHadoop\t1\nHello\t2\n```\n\n- wordcount的执行速度取决于机器性能....\n\n##四. N节点Hadoop集群搭建步骤\n\n###1. 准备工作\n\n- 参考第二部分1~3：下载镜像，修改tag，下载源代码\n- 注意，你可以不下载serf-dnsmasq, 但是请最好下载hadoop-base，因为hadoop-master是基于hadoop-base构建的\n\n###2. 重新构建hadoop-master镜像\n\n```sh\n./resize-cluster.sh 5\n```\n\n- 不要担心，1分钟就能搞定\n- 你可以为resize-cluster.sh脚本设不同的正整数作为参数数1, 2, 3, 4, 5, 6...\n\n###3. 启动容器\n\n```sh\n./start-container.sh 5\n```\n\n- 你可以为resize-cluster.sh脚本设不同的正整数作为参数数1, 2, 3, 4, 5, 6...\n- 这个参数呢，最好还是得和上一步的参数一致:)\n- 这个参数如果比上一步的参数大，你多启动的节点，Hadoop不认识它们..\n- 这个参数如果比上一步的参数小，Hadoop觉得少启动的节点挂掉了..\n\n###4. 测试工作\n\n- 参考第三部分5~7：测试容器，开启Hadoop，运行wordcount\n- 请注意，若节点增加，请务必先测试容器，然后再开启Hadoop, 因为serf可能还没有发现所有节点，而dnsmasq的DNS服务器表示还没有配置好服务\n- 测试等待时间取决于机器性能....\n\n***\n**版权声明**\n转载时请注明作者[KiwenLau](http://kiwenlau.com/)以及本文地址：\n[http://kiwenlau.com/2015/06/08/150608-hadoop-cluster-docker/](http://kiwenlau.com/2015/06/08/150608-hadoop-cluster-docker/)\n***","slug":"150608-hadoop-cluster-docker","published":1,"updated":"2015-09-25T07:51:48.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciezdp86c000i6cv7fzvag712"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ciezdp84x00016cv7v0jwx54o","tag_id":"ciezdp85200026cv7p78gntdi","_id":"ciezdp85600056cv73b9ovyil"},{"post_id":"ciezdp84x00016cv7v0jwx54o","tag_id":"ciezdp85500036cv7c46nbozt","_id":"ciezdp85600066cv779jyhf38"},{"post_id":"ciezdp84x00016cv7v0jwx54o","tag_id":"ciezdp85500046cv7yhpjzr6x","_id":"ciezdp85600076cv7159d7c7w"},{"post_id":"ciezdp85h00086cv7bu5iey8n","tag_id":"ciezdp85p00096cv7tnk3p1j7","_id":"ciezdp85p000a6cv7ufje13sz"},{"post_id":"ciezdp85t000b6cv7e54ng8xp","tag_id":"ciezdp85p00096cv7tnk3p1j7","_id":"ciezdp85v000c6cv706v91hhk"},{"post_id":"ciezdp85y000d6cv7gbfgggmy","tag_id":"ciezdp85z000e6cv7gkszszyw","_id":"ciezdp85z000f6cv7v1g1ezod"},{"post_id":"ciezdp864000g6cv76ql9130h","tag_id":"ciezdp85p00096cv7tnk3p1j7","_id":"ciezdp865000h6cv79k3qnz86"},{"post_id":"ciezdp86c000i6cv7fzvag712","tag_id":"ciezdp86d000j6cv7gmbzcby2","_id":"ciezdp86e000k6cv7718s84pz"},{"post_id":"ciezdp86c000i6cv7fzvag712","tag_id":"ciezdp85200026cv7p78gntdi","_id":"ciezdp86f000l6cv7iahtp7gu"}],"Tag":[{"name":"Docker","_id":"ciezdp85200026cv7p78gntdi"},{"name":"Mesos","_id":"ciezdp85500036cv7c46nbozt"},{"name":"Marathon","_id":"ciezdp85500046cv7yhpjzr6x"},{"name":"Linux","_id":"ciezdp85p00096cv7tnk3p1j7"},{"name":"Python","_id":"ciezdp85z000e6cv7gkszszyw"},{"name":"Hadoop","_id":"ciezdp86d000j6cv7gmbzcby2"}]}}